# Gemini AI Analyzer

## Overview

This service endpoint performs the core AI analysis of the pipeline. It retrieves the raw video and comment data from Google Cloud Storage (using a `trackingId`) and executes a map-reduce strategy using the Gemini API.

First, it breaks the comments into smaller chunks for parallel analysis (the "map" phase). Then, it synthesizes these partial analyses into a single, comprehensive report (the "reduce" phase). The final JSON report is saved as a new file (`<trackingId>_analyzed.json`) in the GCS bucket.

## How to Use

The analysis is triggered by making a GET request to the `/magic` endpoint.

*   **Endpoint**: `GET /magic`
*   **Query Parameters**:
    *   `trackingId` (required): The UUID corresponding to a raw data file (`<trackingId>.json`) in GCS, generated by the `/youtube` endpoint.
*   **Example**:
    ```bash
    curl "http://localhost:8080/magic?trackingId=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
    ```

## Key Functions

*   **`gemini_magic.AnalyzeData`**: The main HTTP handler factory. It manages the entire map-reduce workflow, from fetching the source data to uploading the final analysis.

*   **`gemini_magic.chunkComments`**: A utility function that splits the list of comments into smaller, manageable chunks. This is the foundation of the "map" phase, allowing for parallel processing.

*   **Map-Reduce with Goroutines**: The handler launches a separate goroutine for each comment chunk. Each goroutine sends its chunk to the Gemini API with the `mapPrompt`. A `rate.Limiter` is used to avoid exceeding the API's rate limits. The partial results are collected via a channel. Once all chunks are processed, a final call is made to the Gemini API with the `reducePrompt` to generate the final, consolidated analysis.
